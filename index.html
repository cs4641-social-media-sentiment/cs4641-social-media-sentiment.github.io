---
layout: default
title: Home
---
<div id="summary">
  <h1 class="post-title"> Summary Figure </h1>
  <picture>
    <source srcset="{{ site.baseurl }}/assets/summary-figure-bg.png" media="(prefers-color-scheme: dark)"/>
    <img src="{{ site.baseurl }}/assets/summary-figure.png" />
  </picture>
  
</div>
<div id="background">
  <h1 class="post-title"> Background </h1>
  <p> 
    The Covid-19 pandemic has placed a lot of stress on people. It’s important to monitor the potential effects not only on physical wellbeing but also on mental health. Even though one may not be physically ill, the pressures of a pandemic can lead to strained relationships, a sense of isolation, and anxiety for the future. Especially since many individuals are currently staying at home, social media has become an increasingly important center for sharing opinions and voicing frustrations. Our group is looking to determine a relationship between the number of global Covid-19 cases and the sentiments of messages on Twitter; this can shed a light on how the epidemic is affecting society from a psychological point of view.
  </p>
</div>
<div id="methods">
  <h1 class="post-title"> Methods </h1>
  <p> 
    We intend to use the following datasets: 
    <ul>
      <li><a href="https://www.kaggle.com/cosmos98/twitter-and-reddit-sentimental-analysis-dataset">Twitter and Reddit Sentimental analysis Dataset</a></li>
      <li><a href="https://www.kaggle.com/hgultekin/covid19-stream-data">Covid-19 Coronavirus Dataset Worldwide</a></li>
      <li><a href="https://developer.twitter.com/en">Twitter API for Tweets</a></li>
    </ul>
    The datasets we plan on using are from Kaggle which comes with the benefits of preliminary standardization and dataset cleaning. We plan to train our model with a normal set of Twitter posts and then test with sample data that correlates directly to the timeframe of the Covid-19 pandemic. We plan to randomly select around 10% of tweets for both the training and testing in order to keep a cap on the size of our data sets. 
  </p>
  <p>
    For our unsupervised learning approach, we are planning to utilize a natural language encoder (like BERT) to featurize a dataset consisting of tweets and then performing an unsupervised clustering algorithm upon the feature-set to determine what certain tweet clusters have in common.
  </p>
  <p>
    Our first supervised learning approach is using Naive Bayes Classifier, a probabilistic model that determines textual context from trained features.
  </p>
  <p>
    Another technique we intend to apply is recurrent neural networks to process tweets to obtain their sentiment value. These models process variable length inputs, which can be used to capture word context in order to determine the overall sentiment of a message.
  </p>
</div> 
<div id="results">
  <h1 class="post-title"> Results </h1>
    <h3>Unsupervised Learning</h3>
    <p>
      For our unsupervised learning approach, we used a natural language encoder called Bidirectional Encoder Representations from Transformers (BERT) to featurize a dataset consisting of COVID-19 related tweets. We then performed two different unsupervised clustering algorithms, K-Means and Gaussian Mixture Models, upon the feature-set to determine what certain tweet clusters have in common. Additionally, we featurized and clustered a labeled Twitter sentiment dataset (without looking at the labels) for comparison, to determine whether the tweets truly were being clustered by sentiment.
    </p>
    <p>
      Our primary dataset was a <a href="https://www.kaggle.com/gpreda/covid19-tweets">Kaggle dataset</a> consisting of tweets from the “#covid19” hashtag. Each datapoint had thirteen features but for this analysis we only pulled the "text" feature from the csv file since the other attributes like username and user follower count were irrelevant to our subject matter. To process the input data, we also stripped a trailing URL from the end of each entry (which was originally part of the dataset) in order to decrease noise from our results and remove any potential confounding factors. 
    </p>
    <p>
      Our baseline dataset was a Kaggle dataset consisting of tweets that were labeled by sentiment, where the sentiment was +1, -1, or 0, corresponding to positive, negative, and neutral respectively. However, for the training, we only pulled the ‘clean_text’ column and clustered based off of that. Our reasoning for using this dataset for our clustering was that because it had already been labeled for sentiment, we could cluster it into 3 different clusters and compare our results to the original sentiment labels and measure our model’s accuracy that way.
    </p>
    <p>
      In order to improve visualization of the clusters, we also performed principal component analysis (PCA) on the featurized datasets to find the two “most important” components to represent each featurized tweet on a scatter plot. Finally, each point was colored based on the label it was assigned by the clustering algorithm(s).
    </p>
    <p>
      For the clustering, we ran both K-Means and GMM on the encoded dataset. The images can be found below and the overall clustering reveals relatively similar results. The graphs with “Sentiment Twitter Data” in the title represent our baseline sentiment-labeled dataset while the “Covid-19 Twitter Data” graphs are the results from the primary testing dataset.
    </p>
    <img src="{{ site.baseurl }}/assets/unsupervised-results-1.png" />
    <img src="{{ site.baseurl }}/assets/unsupervised-results-2.png" />
    <img src="{{ site.baseurl }}/assets/unsupervised-results-3.png" />
    <img src="{{ site.baseurl }}/assets/unsupervised-results-4.png" />
    <p>
      For K-means, we could not identify an “elbow” when plotting the number of clusters to the objective function value (we went up to 100 clusters). This shows us that the tweets are about vastly different topics and subject to noise.
    </p>
    <img src="{{ site.baseurl }}/assets/unsupervised-results-5.png" />
</div> 
<div id="discussion">
  <h1 class="post-title"> Discussion </h1>
  <h3>Unsupervised Learning</h3>
  <p>
    We found that for our sentiment labeled tweet data, the tweets were divided into three distinct clusters, split by a variable on the x axis. This initially seemed very promising, as our dataset was already labelled based on sentiment on a scale of -1 to 1, which corresponded directly to what our picture showed at first glance. However, upon further inspection, when we compared the labels our clustering gave to the ground truth labels, we found that the predictions had an accuracy of at most 33% every time. This meant that while our model was clustering on some value, it clearly was not clustering around social media sentiment, as its guesses for the tweet sentiments were no better than performing a random selection out of the possible three groupings. Upon further inspection of the tweets themselves, we could not find any real clear indicators on what our model could be clustering on. This was true for both GMM and k-means, as we found from our analysis that both algorithms resulted in clustering accuracy similar to random guesses, meaning that at least in the problem of predicting social media sentiment, our model was unsuccessful.
  </p>
  <p>
    This result wasn’t entirely unexpected since unsupervised learning on sentiment analysis tends to be inconclusive. Even though we weren’t able to draw specific conclusions from the clustering algorithm, we were able to achieve a deeper understanding of our dataset and the BERT language encoder which we plan to use in our supervised learning portion. We are optimistic that supervised learning will yield better results.
  </p>
  <p>
    In regards to how we could further this investigation, we could figure out how to cluster the tweets by the meaning which would require access to a lot more tweets. However, a consideration that our group encountered was resource restrictions. We performed our training on Google Colabotory’s free version, and found that attempting to process and train on more than two thousand tweets from both datasets caused crashes due to a lack of RAM.
  </p>
</div> 
<div id="references">
  <h1 class="post-title"> References </h1>
  <ul>
    <li><a href="http://cs229.stanford.edu/proj2012/MaZhang-LearningToDetectInformationOutbreaksInSocialNetworks.pdf">Learning to Detect Information Outbreaks in Social Networks</a></li>
    <li><a href="http://cs229.stanford.edu/proj2012/ZarghamNassirpourNasiri-ElectronicDevicesSalesPredictionUsingSocialMediaSentimentAnalysis.pdf">Electronic Devices Sales Prediction Using Social Media Sentiment Analysis</a></li>
    <li><a href="https://academic.microsoft.com/paper/40549020/reference/search?q=Twitter%20as%20a%20Corpus%20for%20Sentiment%20Analysis%20and%20Opinion%20Mining&qe=Or(Id%253D2147880316%252CId%253D2097726431%252CId%253D2166706824%252CId%253D1574901103%252CId%253D2022204871%252CId%253D2115023510%252CId%253D2144378002%252CId%253D2087665422%252CId%253D2110278938%252CId%253D33990384%252CId%253D2403515192%252CId%253D1509129286%252CId%253D2041905826%252CId%253D90118760%252CId%253D2041404167)&f=&orderBy=0">Twitter as a Corpus for Sentiment Analysis and Opinion Mining</a></li>
  </ul>
</div> 

